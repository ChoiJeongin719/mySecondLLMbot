import streamlit as st
import os
import time
from openai import OpenAI
import datetime
import uuid
from supabase import create_client, Client  # ì¶”ê°€

# ì‚¬ìš©ì ID ìƒì„± (ì„¸ì…˜ ì‹œì‘ì‹œ í•œë²ˆë§Œ)
if "user_id" not in st.session_state:
    st.session_state.user_id = str(uuid.uuid4())

# Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
supabase_url = st.secrets["SUPABASE_URL"]
supabase_key = st.secrets["SUPABASE_KEY"]
supabase: Client = create_client(supabase_url, supabase_key)

# Page configuration
st.set_page_config(
    page_title="Debate with Greeni: Pet Cloning",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="collapsed"  # ì‚¬ì´ë“œë°” ê¸°ë³¸ ìˆ¨ê¹€ ìƒíƒœë¡œ ì„¤ì •
)

# Initialize session state variables
if "messages" not in st.session_state:
    st.session_state.messages = []

if "conversation_started" not in st.session_state:
    st.session_state.conversation_started = False

if "max_turns" not in st.session_state:
    st.session_state.max_turns = 4  # Default to 4 turns

if "current_turn" not in st.session_state:
    st.session_state.current_turn = 0

if "system_message" not in st.session_state:
    st.session_state.system_message = """You are Greeni, a balanced debate chatbot that discusses controversial topics from multiple perspectives.
For every user prompt, respond with exactly 8 concise and balanced sentences:

The first 4 sentences must oppose the topic.

The next 4 sentences must support the topic.
Avoid using section headers such as "Pros" or "Cons," "For" or "Against."
Keep your tone neutral and informative.
Do not repeat the question.
Do not label your responses. Just give the 8 sentences in one continuous, paragraph-style response."""

if "interaction_start" not in st.session_state:
    st.session_state.interaction_start = None

if "token_usage" not in st.session_state:
    st.session_state.token_usage = {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}

# íŒŒì¼ ìƒë‹¨ì— ì•± ìƒíƒœ ê´€ë¦¬ë¥¼ ìœ„í•œ ë³€ìˆ˜ ì¶”ê°€ (23-27ì¤„ ê·¼ì²˜)

# ì•± ìƒíƒœ ë° ì°¸ê°€ì ID ê´€ë¦¬
if "app_state" not in st.session_state:
    st.session_state.app_state = "participant_id"  # 'participant_id', 'chat', 'survey', 'complete'

if "participant_id" not in st.session_state:
    st.session_state.participant_id = ""

# CSS styling
st.markdown("""
<style>
    .chat-container {
        margin-bottom: 100px;
    }
    
    .user-bubble {
        background-color: #e3f0fd;  /* íŒŒë€ìƒ‰ ê³„ì—´ë¡œ ë³€ê²½: ê¸°ì¡´ #e6f2ff -> #e3f0fd */
        padding: 12px;
        border-radius: 18px 18px 0 18px;
        margin-bottom: 16px;
        text-align: left;
        max-width: 50%;  /* ê¸°ì¡´ 55%ì—ì„œ 50%ë¡œ ë³€ê²½ */
        margin-left: auto;
        box-shadow: 0 1px 2px rgba(0,0,0,0.1);
    }
    
    .bot-bubble {
        background-color: #f1f1f1;
        padding: 12px;
        border-radius: 18px 18px 18px 0;
        margin-bottom: 16px;
        max-width: 50%;  /* ê¸°ì¡´ 55%ì—ì„œ 50%ë¡œ ë³€ê²½ */
        position: relative;
        margin-left: 50px;
        box-shadow: 0 1px 2px rgba(0,0,0,0.1);
    }
    
    .bot-bubble::before {
        content: "";
        width: 40px;
        height: 40px;
        border-radius: 50%;
        background-color: #4CAF50;  /* Green color for Greeni */
        position: absolute;
        left: -50px;
        top: 0;
        background-image: url('https://cdn-icons-png.flaticon.com/512/4712/4712035.png');
        background-size: 60%;
        background-position: center;
        background-repeat: no-repeat;
        box-shadow: 0 1px 2px rgba(0,0,0,0.1);
    }
    
    /* ë§í’ì„  ê¼¬ë¦¬ ì¶”ê°€ */
    .bot-bubble::after {
        content: "";
        position: absolute;
        left: -10px;
        top: 15px;
        width: 0;
        height: 0;
        border-top: 10px solid transparent;
        border-bottom: 10px solid transparent;
        border-right: 10px solid #f1f1f1;
    }
    
    .bot-name {
        font-size: 0.8em;
        color: #4CAF50;  /* Green color for Greeni */
        font-weight: bold;
        margin-bottom: 4px;
        margin-left: 0px;
    }
    
    .system-message {
        background-color: #f8f9fa;
        padding: 15px;
        border-radius: 5px;
        margin-bottom: 20px;
        /* border-left: 4px solid #4CAF50;  <-- ì´ ì¤„ì„ ì‚­ì œ ë˜ëŠ” ì£¼ì„ ì²˜ë¦¬ */
        max-width: 60%;  /* ê¸°ì¡´ 700pxì—ì„œ 60%ë¡œ ë³€ê²½ */
        margin-left: auto;
        margin-right: auto;
    }
    
    .remaining-turns {
        font-size: 1em;
        margin-top: 10px;
        margin-bottom: 20px;
    }
    
    .conversation-starter {
        display: block;
        margin-left: auto;
        margin-right: 0;
        background-color: #2196F3;  /* íŒŒë€ìƒ‰ìœ¼ë¡œ ë³€ê²½: ê¸°ì¡´ #4CAF50 -> #2196F3 */
        color: white;
        border: none;
        border-radius: 20px;
        padding: 10px 20px;
        cursor: pointer;
        margin-top: 10px;
        margin-bottom: 20px;
    }
    
    .instruction-box {
        background-color: #f9f9f9;
        padding: 15px;
        border-radius: 5px;
        margin-bottom: 20px;
    }
    
    .stats-container {
        background-color: #f9f9f9;
        padding: 15px;
        border-radius: 5px;
        margin-top: 20px;
    }
    
    .page-title {
        text-align: center;
        margin-bottom: 20px;
        color: #333;
    }
    
    /* ì‚¬ì´ë“œë°” ì™„ì „íˆ ìˆ¨ê¸°ê¸° */
    [data-testid="stSidebar"] {
        display: none !important;
    }

    /* ë©”ì¸ ì½˜í…ì¸  ì˜ì—­ ë„ˆë¹„ ì¡°ì • */
    .main .block-container {
        max-width: 100%;
        padding-left: 2rem;
        padding-right: 2rem;
    }

    /* ì±„íŒ… ì…ë ¥ì°½ ìœ„ì¹˜ ì¡°ì • (ì‚¬ì´ë“œë°” ì—†ì„ ë•Œ) */
    .stChatFloatingInputContainer {
        width: calc(100% - 4rem) !important; /* ì‚¬ì´ë“œë°” ì—†ì„ ë•Œ ë„ˆë¹„ ì¡°ì • */
    }
</style>
""", unsafe_allow_html=True)

def get_openai_client():
    """Create and return an OpenAI client configured with environment variables"""
    token = st.secrets["OPENAI_API_KEY"]
    endpoint = st.secrets["OPENAI_API_BASE"]
    
    if not token:
        st.error("GitHub token not found in environment variables. Please check your .env file.")
        st.stop()
        
    return OpenAI(
        base_url=endpoint,
        api_key=token,
    )

def generate_response(prompt):
    """Generate a response from the chatbot"""
    if st.session_state.current_turn >= st.session_state.max_turns:
        return "We've reached the maximum number of turns for this conversation. Please reset the conversation to continue."
    
    client = get_openai_client()
    model_name = st.secrets["OPENAI_API_MODEL"]
    
    # Create message history for the API call
    messages = [{"role": "system", "content": st.session_state.system_message}]
    
    # Add conversation history
    for msg in st.session_state.messages:
        messages.append({"role": msg["role"], "content": msg["content"]})
    
    # Add the current prompt
    messages.append({"role": "user", "content": prompt})
    
    try:
        # If this is the first turn, we want to use the predefined response
        if st.session_state.current_turn == 0:
            predefined_response = """Cloning from a deceased pet involves complex stepsâ€”DNA must be extracted from preserved tissue, then an embryo is formed and implanted into a surrogate. Even if the cloned pet looks the same and shares the same genes, it won't have the same memories or personality, and the sense of loss may still remain. There are many abandoned animals waiting to be adopted, and providing care for them may be a more meaningful choice than cloning.

Cloning a deceased pet involves using biotechnology to create a new animal that is genetically identical to the original. For many people, pets are like family, so the idea of meeting them again in any form can be deeply comforting. With today's advanced technology, cloning has become a realistic option. Some also believe it's worth preserving the genes of special animalsâ€”like service dogs or police dogsâ€”through cloning."""
            
            # Update token usage (approximate since we're not actually calling the API)
            st.session_state.token_usage["prompt_tokens"] += len(prompt.split())
            st.session_state.token_usage["completion_tokens"] += len(predefined_response.split())
            st.session_state.token_usage["total_tokens"] += len(prompt.split()) + len(predefined_response.split())
            
            # Increment turn counter
            st.session_state.current_turn += 1
            
            return predefined_response
        
        # For subsequent turns, use the API
        response = client.chat.completions.create(
            model=model_name,
            messages=messages,
            temperature=0.7,
            stream=True
        )
        
        # Initialize placeholder for streaming response
        placeholder = st.empty()
        full_response = ""
        
        # Stream the response
        for chunk in response:
            if chunk.choices and chunk.choices[0].delta.content:
                content_chunk = chunk.choices[0].delta.content
                full_response += content_chunk
                placeholder.markdown(
                    f"<div class='bot-name'>Greeni</div><div class='bot-bubble'>{full_response}â–Œ</div>",
                    unsafe_allow_html=True
                )
        
        # Update the placeholder with the final response (no cursor)
        placeholder.markdown(
            f"<div class='bot-name'>Greeni</div><div class='bot-bubble'>{full_response}</div>",
            unsafe_allow_html=True
        )
        
        # Update token usage (approximate)
        st.session_state.token_usage["prompt_tokens"] += len(prompt.split())
        st.session_state.token_usage["completion_tokens"] += len(full_response.split())
        st.session_state.token_usage["total_tokens"] += len(prompt.split()) + len(full_response.split())
        
        # Increment turn counter
        st.session_state.current_turn += 1
        
        return full_response
        
    except Exception as e:
        st.error(f"Error generating response: {str(e)}")
        return "I'm sorry, I encountered an error while processing your request."

def save_to_supabase(score=None):
    """Supabaseì— ë°ì´í„° ì €ì¥"""
    try:
        # ì‹œê°„ ì •ë³´ ê³„ì‚°
        if st.session_state.interaction_start:
            start_time = st.session_state.interaction_start
            end_time = datetime.datetime.now()
            elapsed = end_time - start_time
            duration_seconds = int(elapsed.total_seconds())  # ì´ˆ ë‹¨ìœ„ ì •ìˆ˜
            interaction_time = duration_seconds  # ì´ˆ ë‹¨ìœ„ ì •ìˆ˜ë¥¼ ì €ì¥
        else:
            start_time = datetime.datetime.now()  # ì‹œì‘ ì‹œê°„ì´ ì—†ìœ¼ë©´ í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ì„¤ì •
            end_time = None
            interaction_time = None
        
        # ì €ì¥í•  ë°ì´í„° ì¤€ë¹„ (í…Œì´ë¸” êµ¬ì¡°ì— ë§ê²Œ ì¡°ì •)
        data = {
            # timestampëŠ” ê¸°ë³¸ê°’ now()ë¥¼ ì‚¬ìš©
            "user_id": st.session_state.user_id,
            "participant_id": st.session_state.participant_id,  # ì°¸ê°€ì ID ì¶”ê°€
            "started_at": start_time.isoformat(),  # ì‹œì‘ ì‹œê°„ ì¶”ê°€ (ISO í˜•ì‹ ë¬¸ìì—´ë¡œ ë³€í™˜)
            "finished_at": end_time.isoformat() if end_time else None,  # ì¢…ë£Œ ì‹œê°„ ì¶”ê°€
            "interaction_time": interaction_time,  # ì´ˆ ë‹¨ìœ„ ì •ìˆ˜ë¡œ ì €ì¥
            "total_tokens": st.session_state.token_usage["total_tokens"],
            "prompt_tokens": st.session_state.token_usage["prompt_tokens"],
            "completion_tokens": st.session_state.token_usage["completion_tokens"],
            "score": score,
            "messages": st.session_state.messages
        }
        
        # Supabaseì— ë°ì´í„° ì €ì¥
        result = supabase.table("LLM1_R").insert(data).execute()
        
        # ì €ì¥ ì„±ê³µ ì—¬ë¶€ í™•ì¸
        if result.data:
            return True
        return False
    
    except Exception as e:
        st.error(f"ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

def validate_participant_id(participant_id):
    """
    Validate participant ID from Supabase participants table
    
    Returns:
        (bool, str): (valid, message)
    """
    try:
        # Master key check
        if participant_id == "j719":
            return True, "Admin access confirmed"
        
        # Format check: a, b, c, d followed by 3 digits (001~100)
        import re
        if not re.match(r'^[a-d][0-9]{3}$', participant_id):
            return False, "Invalid participant ID format. Must be a, b, c, or d + 3 digits (e.g., a001)"
        
        # Check if number part is in 001-100 range
        num_part = int(participant_id[1:])
        if num_part < 1 or num_part > 100:
            return False, "Invalid participant ID. Number must be in 1-100 range."
        
        # Look up ID in Supabase
        result = supabase.table("participants").select("*").eq("id", participant_id).execute()
        
        # If ID doesn't exist in participants table
        if not result.data:
            return False, "Participant ID not registered."
        
        # Check if ID is already used
        if result.data[0].get("used", False):
            return False, "This participant ID has already been used."
        
        # If valid ID, update used status
        supabase.table("participants").update({"used": True, "used_at": datetime.datetime.now().isoformat()}).eq("id", participant_id).execute()
        return True, "Participant verified successfully."
    
    except Exception as e:
        st.error(f"Error validating participant ID: {str(e)}")
        return False, f"An error occurred: {str(e)}"

# Sidebar for settings
with st.sidebar:
    st.header("Settings")
    
    # Max turns selection
    st.session_state.max_turns = st.selectbox(
        "Number of turns:",
        options=list(range(1, 11)),
        index=3  # Default to 4 turns (index 3 = 4)
    )
    
    # Display stats in sidebar
    if st.session_state.interaction_start:
        st.markdown("---")
        st.subheader("Interaction Stats")
        
        # Calculate elapsed time
        elapsed_time = datetime.datetime.now() - st.session_state.interaction_start
        elapsed_seconds = elapsed_time.total_seconds()
        minutes = int(elapsed_seconds // 60)
        seconds = int(elapsed_seconds % 60)
        
        st.markdown(f"**Interaction time:** {minutes} min {seconds} sec")
        st.markdown(f"**Turns used:** {st.session_state.current_turn} / {st.session_state.max_turns}")
        st.markdown("**Token Usage:**")
        st.markdown(f"- Total: {st.session_state.token_usage['total_tokens']}")
        st.markdown(f"- Prompt: {st.session_state.token_usage['prompt_tokens']}")
        st.markdown(f"- Completion: {st.session_state.token_usage['completion_tokens']}")
    
    # System message editor
    st.markdown("---")
    st.subheader("System Message")
    system_message = st.text_area(
        "Edit the system message:",
        value=st.session_state.system_message,
        height=200
    )
    
    if st.button("Update System Message"):
        st.session_state.system_message = system_message
        st.success("System message updated!")
    
    # Reset conversation button
    st.markdown("---")
    if st.button("Reset Conversation"):
        # ê¸°ì¡´ ëŒ€í™”ê°€ ìˆìœ¼ë©´ ì €ì¥
        if st.session_state.conversation_started and st.session_state.messages:
            save_to_supabase(None)  # scoreëŠ” Noneìœ¼ë¡œ ì €ì¥
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        st.session_state.messages = []
        st.session_state.conversation_started = False
        st.session_state.current_turn = 0
        st.session_state.interaction_start = None
        st.session_state.token_usage = {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
        st.success("Conversation reset!")

# ì„¤ë¬¸ì¡°ì‚¬ í˜ì´ì§€ í‘œì‹œ ì—¬ë¶€ë¥¼ ìœ„í•œ ìƒíƒœ ë³€ìˆ˜ ì¶”ê°€
if "show_survey" not in st.session_state:
    st.session_state.show_survey = False

# Next ë²„íŠ¼ í´ë¦­ ì—¬ë¶€ë¥¼ ì €ì¥í•˜ëŠ” ìƒíƒœ ë³€ìˆ˜ ì¶”ê°€
if "next_clicked" not in st.session_state:
    st.session_state.next_clicked = False

# ì±„íŒ…ì´ ëë‚¬ì„ ë•Œ Next ë²„íŠ¼ í‘œì‹œ ì—¬ë¶€ë¥¼ ìœ„í•œ ìƒíƒœ ë³€ìˆ˜
if "show_next_button" not in st.session_state:
    st.session_state.show_next_button = False

# ì±„íŒ…ì´ ëë‚¬ìœ¼ë©´ Next ë²„íŠ¼ í‘œì‹œ
if (
    st.session_state.conversation_started
    and st.session_state.current_turn >= st.session_state.max_turns
    and not st.session_state.show_survey
    and not st.session_state.next_clicked
):
    st.session_state.show_next_button = True

# Next ë²„íŠ¼ì´ í´ë¦­ë˜ë©´ ì„¤ë¬¸ì¡°ì‚¬ í˜ì´ì§€ë¡œ ì´ë™
def on_next_click():
    st.session_state.next_clicked = True
    st.session_state.show_survey = True
    st.session_state.show_next_button = False

# ì±„íŒ… í˜ì´ì§€ ìƒë‹¨ì— ì°¸ê°€ì ID í‘œì‹œ ì¶”ê°€
def show_chat_page():
    # ìƒë‹¨ì— ì°¸ê°€ì ID í‘œì‹œ
    st.markdown(f"<div style='text-align: right; font-size: 0.8em; color: #666;'>Participant ID: {st.session_state.participant_id}</div>", unsafe_allow_html=True)
    
    # ì„¤ë¬¸ ì¡°ì‚¬ ë˜ëŠ” ì±„íŒ… UI í‘œì‹œ
    if st.session_state.show_survey:
        st.markdown("<h2>Survey</h2>", unsafe_allow_html=True)
        st.markdown("**Do you want to talk more with this chatbot?**")
        
        # ìŠ¬ë¼ì´ë” UI ê°œì„ 
        col1, col2, col3 = st.columns([1, 10, 1])
        
        with col1:
            st.markdown("<div style='text-align: center; font-size: 0.9em;'>(Disagree)</div>", unsafe_allow_html=True)
            
        with col2:
            score = st.slider("", 1, 9, 5, label_visibility="collapsed")
            
        with col3:
            st.markdown("<div style='text-align: center; font-size: 0.9em;'>(Agree)</div>", unsafe_allow_html=True)
        
        if st.button("Submit Survey"):
            # Supabaseì— ë°ì´í„° ì €ì¥
            if save_to_supabase(score):
                st.success(f"Thank you for your feedback! Your score: {score}")
            else:
                st.warning("í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆì§€ë§Œ, ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ì— ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤.")
            
            # ì¼ì • ì‹œê°„ í›„ ì™„ë£Œ í˜ì´ì§€ë¡œ ì´ë™
            time.sleep(2)
            
            # ì•± ìƒíƒœë¥¼ ì™„ë£Œ í˜ì´ì§€ë¡œ ì„¤ì •
            st.session_state.app_state = "complete"
            st.rerun()
    else:
        # ê¸°ì¡´ ì±„íŒ… UI ì½”ë“œ
        st.markdown("<div class='chat-container'>", unsafe_allow_html=True)

        # Display the introductory message with reduced width
        st.markdown(
            "<div class='system-message'>You will engage in a four-turn conversation with a chatbot about \"Cloning of a deceased pet\". "
            "Click the button with the question to begin the first turn. "
            "After that, you will have three more turns to continue the conversation by typing freely. Start the conversation â€” Greeni will respond to your messages.</div>",
            unsafe_allow_html=True
        )

        # Display remaining turns
        st.markdown(
            f"<div class='remaining-turns'>Remaining turns: {st.session_state.max_turns - st.session_state.current_turn}</div>",
            unsafe_allow_html=True
        )

        # Conversation starter button
        col1, col2 = st.columns([3, 1])
        with col2:
            if not st.session_state.conversation_started and st.button(
                "Greeni, can you tell me about cloning of a deceased pet?", 
                key="conversation_starter",
            ):
                # Start tracking time
                st.session_state.interaction_start = datetime.datetime.now()
                
                # Set conversation as started
                st.session_state.conversation_started = True
                
                # Add user message
                prompt = "Greeni, can you tell me about cloning of a deceased pet?"
                st.session_state.messages.append({"role": "user", "content": prompt})
                
                # Generate and add bot response
                response = generate_response(prompt)
                st.session_state.messages.append({"role": "assistant", "content": response})
                
                # Force a rerun to show the messages
                st.rerun()

        # Display chat messages
        for message in st.session_state.messages:
            if message["role"] == "user":
                st.markdown(
                    f"<div class='user-bubble'>{message['content']}</div>",
                    unsafe_allow_html=True
                )
            else:
                st.markdown(
                    f"<div class='bot-name'>Greeni</div><div class='bot-bubble'>{message['content']}</div>",
                    unsafe_allow_html=True
                )

        # Next ë²„íŠ¼ í‘œì‹œ (ëŒ€í™”ê°€ ëª¨ë‘ ëë‚¬ì„ ë•Œ)
        if st.session_state.show_next_button:
            st.button("Next â†’", on_click=on_next_click, type="primary")

        st.markdown("</div>", unsafe_allow_html=True)

        # Chat input (only show if conversation has started and max turns not reached)
        if st.session_state.conversation_started and st.session_state.current_turn < st.session_state.max_turns:
            prompt = st.chat_input("Type your message here...")
            if prompt:
                # Add user message
                st.session_state.messages.append({"role": "user", "content": prompt})
                
                # Generate and add bot response
                response = generate_response(prompt)
                st.session_state.messages.append({"role": "assistant", "content": response})
                
                # Force a rerun to show the messages
                st.rerun()

def show_participant_id_page():
    st.title("Participant Information")
    
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        st.markdown("### Please enter your participant ID")
        st.markdown("Enter the participant ID provided for this experiment.")
        
        # Participant ID input field
        participant_id = st.text_input(
            "Participant ID", 
            value=st.session_state.participant_id,
            key="participant_id_input",
            placeholder="e.g., a001"
        )
        
        # Start experiment button
        if st.button("Start Experiment", type="primary", key="start_experiment_btn"):
            # Validate participant ID
            valid, message = validate_participant_id(participant_id)
            
            if valid:
                st.session_state.participant_id = participant_id
                st.session_state.app_state = "chat"
                st.success(message)
                time.sleep(1)  # Show success message briefly
                st.rerun()
            else:
                st.error(message)

def show_complete_page():
    """ì™„ë£Œ í˜ì´ì§€ í‘œì‹œ"""
    # ì¤‘ì•™ ì •ë ¬ì„ ìœ„í•œ ì»¬ëŸ¼ ì‚¬ìš©
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        st.markdown("<h1 style='text-align: center; margin-top: 100px;'>Thank you for your participation!</h1>", unsafe_allow_html=True)
        
        # ë‹¤ì‹œ ì‹œì‘ ë²„íŠ¼ (ì˜µì…˜)
        st.markdown("<div style='text-align: center; margin-top: 50px;'>", unsafe_allow_html=True)
        if st.button("Start a new conversation", type="primary", key="restart_btn"):
            # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.app_state = "participant_id"
            st.session_state.participant_id = ""
            st.session_state.messages = []
            st.session_state.conversation_started = False
            st.session_state.current_turn = 0
            st.session_state.interaction_start = None
            st.session_state.token_usage = {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
            st.session_state.show_survey = False
            st.session_state.next_clicked = False
            st.session_state.show_next_button = False
            st.rerun()
        st.markdown("</div>", unsafe_allow_html=True)

# ì•± ìƒíƒœì— ë”°ë¼ ë‹¤ë¥¸ UI í‘œì‹œ
if st.session_state.app_state == "participant_id":
    show_participant_id_page()
elif st.session_state.app_state == "chat":
    show_chat_page()
elif st.session_state.app_state == "complete":
    show_complete_page()