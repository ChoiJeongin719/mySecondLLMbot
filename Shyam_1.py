import os
import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv
import json
import glob
import datetime  # ì‹œê°„ ì¸¡ì •ì„ ìœ„í•´ ì¶”ê°€

# Load environment variables from .env file
load_dotenv()

# Set page config
st.set_page_config(
    page_title="ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="wide"
)

# Initialize session state variables if they don't exist
if "messages" not in st.session_state:
    st.session_state.messages = []  # ì•ˆë‚´ ë¬¸êµ¬ ì œê±°

if "system_message" not in st.session_state:
    st.session_state.system_message = "ë‹¹ì‹ ì€ ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ëŠ” ì¹œì ˆí•œ ì±—ë´‡ì…ë‹ˆë‹¤. ë…¼ë¦¬ì ì´ê³  ë„ì›€ì´ ë˜ëŠ” ëŒ€ë‹µì„ í•´ì£¼ì„¸ìš”. ê°„ê²°í•˜ê²Œ ë°˜ë§ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì°¬ì„±ì˜ê²¬ 4ë¬¸ì¥ì„ ë§í•˜ê³  ë‹¤ìŒ ë¬¸ë‹¨ì—ì„œëŠ” ë°˜ëŒ€ ì˜ê²¬ 4ë¬¸ì¥ì„ ë§í•˜ì„¸ìš”. ì°¬ì„±, ë°˜ëŒ€ë¼ê³  ë¼ë²¨ë§í•˜ì§€ ë§ˆì„¸ìš”."

if "usage_stats" not in st.session_state:
    st.session_state.usage_stats = []

if "show_process" not in st.session_state:
    st.session_state.show_process = False

# ëŒ€í™” í„´ ì œí•œì„ ìœ„í•œ ë³€ìˆ˜ ì¶”ê°€
if "max_turns" not in st.session_state:
    st.session_state.max_turns = 10

if "turn_count" not in st.session_state:
    st.session_state.turn_count = 0

if "chat_completed" not in st.session_state:
    st.session_state.chat_completed = False

# ëŒ€í™” ìŠ¤íƒ€í„° ì‚¬ìš© ì—¬ë¶€ ì¶”ì 
if "starter_selected" not in st.session_state:
    st.session_state.starter_selected = False

# ì‹œì‘ í† í”½ ì €ì¥ì„ ìœ„í•œ ë³€ìˆ˜
if "start_with_topic" not in st.session_state:
    st.session_state.start_with_topic = None

# ì„¸ì…˜ ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ ë³€ìˆ˜ë“¤ ì¶”ê°€
if "session_start_time" not in st.session_state:
    st.session_state.session_start_time = datetime.datetime.now()

if "last_interaction_time" not in st.session_state:
    st.session_state.last_interaction_time = datetime.datetime.now()

if "total_session_duration" not in st.session_state:
    st.session_state.total_session_duration = datetime.timedelta(0)

if "interaction_count" not in st.session_state:
    st.session_state.interaction_count = 0

# ì‚¬ìš© ì‹œê°„ ê¸°ë¡ í•¨ìˆ˜
def update_session_time():
    """í˜„ì¬ ì„¸ì…˜ì˜ ì‚¬ìš© ì‹œê°„ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤"""
    now = datetime.datetime.now()
    
    # ë§ˆì§€ë§‰ ìƒí˜¸ì‘ìš© ì´í›„ 10ë¶„(600ì´ˆ) ì´ìƒ ì§€ë‚¬ë‹¤ë©´ ìƒˆ ì„¸ì…˜ìœ¼ë¡œ ê°„ì£¼
    time_diff = (now - st.session_state.last_interaction_time).total_seconds()
    if time_diff > 600:  # 10ë¶„ ì´ìƒ ì°¨ì´
        # ì´ì „ ì„¸ì…˜ ì‹œê°„ ì €ì¥
        session_duration = st.session_state.last_interaction_time - st.session_state.session_start_time
        st.session_state.total_session_duration += session_duration
        
        # ìƒˆ ì„¸ì…˜ ì‹œì‘
        st.session_state.session_start_time = now
    
    # ë§ˆì§€ë§‰ ìƒí˜¸ì‘ìš© ì‹œê°„ ì—…ë°ì´íŠ¸
    st.session_state.last_interaction_time = now
    
    # ìƒí˜¸ì‘ìš© íšŸìˆ˜ ì¦ê°€
    st.session_state.interaction_count += 1

def get_openai_client():
    """Create and return an OpenAI client configured with environment variables"""
    token = os.getenv("GITHUB_TOKEN")
    endpoint = os.getenv("GITHUB_ENDPOINT", "https://models.github.ai/inference")
    
    if not token:
        st.error("GitHub token not found in environment variables. Please check your .env file.")
        st.stop()
        
    return OpenAI(
        base_url=endpoint,
        api_key=token,
    )

def generate_response(prompt):
    """Generate a response to the user's prompt"""
    # ëŒ€í™” í„´ ì œí•œ í™•ì¸
    if st.session_state.turn_count >= st.session_state.max_turns:
        st.warning("ëŒ€í™” í„´ ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ì±„íŒ…ì„ ì´ˆê¸°í™”í•˜ê³  ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”.")
        return False
        
    # ìƒí˜¸ì‘ìš© ì‹œê°„ ì—…ë°ì´íŠ¸
    update_session_time()
    
    # í„´ ìˆ˜ ì¦ê°€
    st.session_state.turn_count += 1
    
    client = get_openai_client()
    model_name = os.getenv("GITHUB_MODEL", "openai/gpt-4o")
    
    # Prepare previous conversation history (excluding the system message)
    history = []
    for msg in st.session_state.messages:
        if msg["role"] != "system" and "type" not in msg:  # Skip system messages
            history.append(msg)
    
    # ë©”ì‹œì§€ ìƒì„±
    messages = [{"role": "system", "content": st.session_state.system_message}] + history + [{"role": "user", "content": prompt}]
    
    try:
        # ì±„íŒ…ë°© í˜•ì‹ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ì‘ë‹µ í‘œì‹œ
        status_placeholder = st.empty()
        status_placeholder.markdown("ì‘ë‹µ ìƒì„± ì¤‘...", unsafe_allow_html=True)
        
        # ì‘ë‹µ ìƒì„±
        full_response = ""
        usage_data = None
        
        response = client.chat.completions.create(
            messages=messages,
            model=model_name,
            stream=True,
            stream_options={'include_usage': True}
        )
        
        # ì‘ë‹µ ì¶”ê°€
        response_placeholder = st.empty()
        
        # ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
        for chunk in response:
            if chunk.choices and chunk.choices[0].delta.content:
                content_chunk = chunk.choices[0].delta.content
                full_response += content_chunk
                response_placeholder.markdown(
                    f"<div class='bot-name'>ì´ˆë¡ì´</div><div class='bot-bubble'>{full_response}â–Œ</div>",
                    unsafe_allow_html=True
                )
                
            if chunk.usage:
                usage_data = chunk.usage
        
        # ìµœì¢… ì‘ë‹µ ì—…ë°ì´íŠ¸ (ì»¤ì„œ ì œê±°)
        response_placeholder.markdown(
            f"<div class='bot-name'>ì´ˆë¡ì´</div><div class='bot-bubble'>{full_response}</div>",
            unsafe_allow_html=True
        )
        
        # ìƒíƒœ í‘œì‹œ ì œê±°
        status_placeholder.empty()
        
        # ì‘ë‹µì„ ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€
        st.session_state.messages.append({"role": "assistant", "content": full_response, "type": "bot"})
        
        # ì‚¬ìš©ëŸ‰ í†µê³„ ì €ì¥
        if usage_data:
            # Pydantic ì²˜ë¦¬
            usage_dict = usage_data.model_dump() if hasattr(usage_data, 'model_dump') else usage_data.dict()
            
            st.session_state.usage_stats.append({
                "prompt_tokens": usage_dict.get("prompt_tokens", 0),
                "completion_tokens": usage_dict.get("completion_tokens", 0),
                "total_tokens": usage_dict.get("total_tokens", 0)
            })
        
        # í”„ë¡œì„¸ìŠ¤ í‘œì‹œ í™œì„±í™”ëœ ê²½ìš°
        if st.session_state.show_process:
            process_container = st.container()
            with process_container:
                st.markdown("### ëª¨ë¸ ì²˜ë¦¬ ê³¼ì •")
                
                # ìš”ì²­ ìƒì„¸ ì •ë³´ í‘œì‹œ
                request_expander = st.expander("ìš”ì²­ ìƒì„¸ ì •ë³´", expanded=False)
                with request_expander:
                    st.markdown("**ì‹œìŠ¤í…œ ë©”ì‹œì§€:**")
                    st.code(st.session_state.system_message)
                    st.markdown("**ì‚¬ìš©ì ì…ë ¥:**")
                    st.code(prompt)
                
                # ì›ì‹œ ì‘ë‹µ í‘œì‹œ
                response_expander = st.expander("ì›ì‹œ ì‘ë‹µ", expanded=False)
                with response_expander:
                    st.markdown("**ì‘ë‹µ:**")
                    st.code(full_response, language="markdown")
                
                # ì‚¬ìš©ëŸ‰ í†µê³„ í‘œì‹œ
                if usage_data:
                    usage_expander = st.expander("ì‚¬ìš©ëŸ‰ í†µê³„", expanded=False)
                    with usage_expander:
                        st.markdown("**ì‘ë‹µ ì‚¬ìš©ëŸ‰:**")
                        st.markdown(f"- í”„ë¡¬í”„íŠ¸ í† í°: {usage_dict.get('prompt_tokens', 0)}")
                        st.markdown(f"- ì‘ë‹µ í† í°: {usage_dict.get('completion_tokens', 0)}")
                        st.markdown(f"- ì´ í† í°: {usage_dict.get('total_tokens', 0)}")
        
        # ìµœëŒ€ í„´ìˆ˜ ë„ë‹¬ì‹œ ì±„íŒ… ì™„ë£Œ ì„¤ì •
        if st.session_state.turn_count >= st.session_state.max_turns:
            st.session_state.chat_completed = True
        
        return True
    except Exception as e:
        st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

# CSS ìŠ¤íƒ€ì¼ ì •ì˜ ìˆ˜ì •
st.markdown("""
    <style>
    .bot-bubble {
        background-color: #f1f1f1;
        padding: 12px;
        border-radius: 18px 18px 18px 0;
        margin-bottom: 16px;
        max-width: 45%;
        position: relative;
        margin-left: 50px;
        box-shadow: 0 1px 2px rgba(0,0,0,0.1);
    }

    .bot-bubble::before {
        content: "";
        width: 40px;
        height: 40px;
        border-radius: 50%;
        background-color: #4CAF50;  /* ì´ˆë¡ìƒ‰ */
        position: absolute;
        left: -50px;
        top: 0;
        background-image: url('https://cdn-icons-png.flaticon.com/512/4712/4712035.png');
        background-size: 60%;
        background-position: center;
        background-repeat: no-repeat;
        box-shadow: 0 1px 2px rgba(0,0,0,0.1);
    }

    .user-bubble {
        background-color: #e6f2ff;
        padding: 12px;
        border-radius: 18px 18px 0 18px;
        margin-bottom: 16px;
        text-align: left;
        max-width: 45%;
        margin-left: auto;
        box-shadow: 0 1px 2px rgba(0,0,0,0.1);
    }

    .system-bubble {
        background-color: #f8f9fa;
        padding: 12px;
        border-radius: 18px;
        margin-bottom: 16px;
        max-width: 45%;
        margin-left: auto;
        margin-right: auto;
        text-align: center;
        box-shadow: 0 1px 2px rgba(0,0,0,0.1);
    }

    .stChatFloatingInputContainer {
        position: fixed !important;
        bottom: 0 !important;
        padding: 1rem !important;
        width: calc(100% - 250px) !important; /* ì‚¬ì´ë“œë°” ë„ˆë¹„ ì¡°ì • */
        background-color: white !important;
        z-index: 1000 !important;
    }

    .main-content {
        padding-bottom: 100px; /* ê³ ì • ì…ë ¥ì°½ì„ ìœ„í•œ í•˜ë‹¨ ì—¬ë°± */
    }

    .bot-name {
        font-size: 0.8em;
        color: #4CAF50;  /* ì´ˆë¡ìƒ‰ */
        font-weight: bold;
        margin-bottom: 4px;
        margin-left: 0px;
    }
    </style>
""", unsafe_allow_html=True)

# UI Layout
st.title("ğŸ¤– ì±—ë´‡")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.subheader("ì„¤ì •")
    
    # ìµœëŒ€ í„´ ìˆ˜ ì„¤ì •
    st.markdown("---")
    st.subheader("ëŒ€í™” ì„¤ì •")
    
    # ì±„íŒ…ì´ ì™„ë£Œë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ í„´ ìˆ˜ ì„¤ì • ê°€ëŠ¥
    if not st.session_state.chat_completed:
        new_max_turns = st.slider(
            "ìµœëŒ€ í„´ ìˆ˜", 
            min_value=1, 
            max_value=10, 
            value=st.session_state.max_turns
        )
        if new_max_turns != st.session_state.max_turns:
            st.session_state.max_turns = new_max_turns
            st.success(f"ìµœëŒ€ í„´ ìˆ˜ê°€ {new_max_turns}ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        st.info(f"í˜„ì¬ ì„¤ì •ëœ ìµœëŒ€ í„´ ìˆ˜: {st.session_state.max_turns} (ì±„íŒ… ì´ˆê¸°í™” í›„ ë³€ê²½ ê°€ëŠ¥)")
    
    # ì‹œê°„ ì¸¡ì • í†µê³„ í‘œì‹œ
    with st.expander("ì‚¬ìš© ì‹œê°„ í†µê³„", expanded=False):
        # í˜„ì¬ ì„¸ì…˜ ê³„ì‚°
        current_session_duration = st.session_state.last_interaction_time - st.session_state.session_start_time
        total_time = st.session_state.total_session_duration + current_session_duration
        
        # ì‹œê°„ í˜•ì‹ ì§€ì • (ì‹œ:ë¶„:ì´ˆ)
        def format_timedelta(td):
            total_seconds = int(td.total_seconds())
            hours = total_seconds // 3600
            minutes = (total_seconds % 3600) // 60
            seconds = total_seconds % 60
            return f"{hours:02d}:{minutes:02d}:{seconds:02d}"
        
        st.write("### ì‚¬ìš© ì‹œê°„")
        st.write(f"í˜„ì¬ ì„¸ì…˜: {format_timedelta(current_session_duration)}")
        st.write(f"ì´ ì‚¬ìš© ì‹œê°„: {format_timedelta(total_time)}")
        st.write(f"ì´ ìƒí˜¸ì‘ìš© íšŸìˆ˜: {st.session_state.interaction_count}")
        st.write(f"ì²« ì‚¬ìš© ì‹œê°„: {st.session_state.session_start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        st.write(f"ë§ˆì§€ë§‰ ì‚¬ìš© ì‹œê°„: {st.session_state.last_interaction_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìˆ˜ì •
    st.text_area(
        "ì±—ë´‡ ì„¤ì •", 
        value=st.session_state.system_message,
        key="system_message_input",
        height=150
    )
    
    if st.button("ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸"):
        st.session_state.system_message = st.session_state.system_message_input
        st.success("ì‹œìŠ¤í…œ ë©”ì‹œì§€ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ê¸°íƒ€ ì‚¬ì´ë“œë°” ìš”ì†Œ
    st.markdown("---")
    
    # ì±„íŒ… ê¸°ë¡ ë³´ê¸°
    with st.expander("ì±„íŒ… ê¸°ë¡ ë³´ê¸°"):
        st.json(st.session_state.messages)
    
    # ì‚¬ìš©ëŸ‰ í†µê³„ ë³´ê¸°
    with st.expander("ì‚¬ìš©ëŸ‰ í†µê³„ ë³´ê¸°"):
        if st.session_state.usage_stats:
            for i, usage in enumerate(st.session_state.usage_stats):
                st.write(f"ë©”ì‹œì§€ {i+1}:")
                st.write(f"- í”„ë¡¬í”„íŠ¸ í† í°: {usage['prompt_tokens']}")
                st.write(f"- ì‘ë‹µ í† í°: {usage['completion_tokens']}")
                st.write(f"- ì´ í† í°: {usage['total_tokens']}")
                st.divider()
            
            # ì´ ì‚¬ìš©ëŸ‰ ê³„ì‚°
            total_prompt = sum(u["prompt_tokens"] for u in st.session_state.usage_stats)
            total_completion = sum(u["completion_tokens"] for u in st.session_state.usage_stats)
            total = sum(u["total_tokens"] for u in st.session_state.usage_stats)
            
            st.write("### ì´ ì‚¬ìš©ëŸ‰")
            st.write(f"- ì´ í”„ë¡¬í”„íŠ¸ í† í°: {total_prompt}")
            st.write(f"- ì´ ì‘ë‹µ í† í°: {total_completion}")
            st.write(f"- ì´ í† í°: {total}")
        else:
            st.write("ì•„ì§ ì‚¬ìš©ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì±„íŒ… ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ì±„íŒ… ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.session_state.usage_stats = []
        
        # ëŒ€í™” ìŠ¤íƒ€í„° ì´ˆê¸°í™”
        st.session_state.starter_selected = False
        
        # í„´ ìˆ˜ ì´ˆê¸°í™”
        st.session_state.turn_count = 0
        st.session_state.chat_completed = False
        
        # ì‹œê°„ ê´€ë ¨ ë³€ìˆ˜ë„ ì´ˆê¸°í™”
        now = datetime.datetime.now()
        st.session_state.session_start_time = now
        st.session_state.last_interaction_time = now
        st.session_state.total_session_duration = datetime.timedelta(0)
        st.session_state.interaction_count = 0
        
        st.success("ì±„íŒ… ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # í”„ë¡œì„¸ìŠ¤ í‘œì‹œ í† ê¸€
    st.markdown("---")
    st.session_state.show_process = st.checkbox("ëª¨ë¸ ì²˜ë¦¬ ê³¼ì • ë³´ê¸°", value=st.session_state.show_process)

# ë©”ì¸ ì±„íŒ… ì˜ì—­
chat_container = st.container()
with chat_container:
    st.markdown('<div class="main-content">', unsafe_allow_html=True)
    
    # ëŒ€í™” ìŠ¤íƒ€í„° í‘œì‹œ (ì²˜ìŒ ë°©ë¬¸í•˜ê³  ì•„ì§ ì„ íƒí•˜ì§€ ì•Šì•˜ì„ ë•Œë§Œ)
    if len(st.session_state.messages) == 0 and not st.session_state.starter_selected:
        st.markdown("""
        <div style='text-align: center; margin: 50px 0 30px 0;'>
            <h3>ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ëŒ€í™”ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”</h3>
        </div>
        """, unsafe_allow_html=True)
        
        # ì¤‘ì•™ì— ë²„íŠ¼ ë°°ì¹˜
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            starter_topic = "ë™ë¬¼ ì•ˆë½ì‚¬ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜"
            if st.button("ë™ë¬¼ ì•ˆë½ì‚¬ê°€ ë­ì•¼?", key="starter_btn", use_container_width=True):
                # ë¨¼ì € ìŠ¤íƒ€í„° í† í”½ ì„ íƒ ìƒíƒœë¥¼ ë³€ê²½
                st.session_state.starter_selected = True
                
                # ë‹¤ìŒ í˜ì´ì§€ ë¡œë“œì—ì„œ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ë„ë¡ ì„¸ì…˜ ìƒíƒœ ì„¤ì •
                st.session_state.start_with_topic = starter_topic
                st.rerun()
    
    # ê¸°ì¡´ ì±„íŒ… ê¸°ë¡ ì²˜ë¦¬ ì½”ë“œ
    i = 0
    while i < len(st.session_state.messages):
        message = st.session_state.messages[i]
        
        if message["role"] == "user":
            # ì‚¬ìš©ì ë©”ì‹œì§€
            st.markdown(
                f"<div class='user-bubble'>{message['content']}</div>",
                unsafe_allow_html=True
            )
            i += 1
        elif message["role"] == "assistant" and "type" in message and message["type"] == "system":
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€
            st.markdown(
                f"<div class='system-bubble'>{message['content']}</div>",
                unsafe_allow_html=True
            )
            i += 1
        elif message["role"] == "assistant" and "type" in message and message["type"] == "bot":
            # ì±—ë´‡ ë©”ì‹œì§€ - ì´ˆë¡ìƒ‰ í”„ë¡œí•„ë¡œ í‘œì‹œ
            st.markdown(
                f"<div class='bot-name'>ì´ˆë¡ì´</div><div class='bot-bubble'>{message['content']}</div>",
                unsafe_allow_html=True
            )
            i += 1
        else:
            # ê¸°íƒ€ ë©”ì‹œì§€
            st.markdown(
                f"<div class='system-bubble'>{message['content']}</div>",
                unsafe_allow_html=True
            )
            i += 1
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # ë‚¨ì€ í„´ ìˆ˜ í‘œì‹œ
    if not st.session_state.chat_completed:
        remaining_turns = st.session_state.max_turns - st.session_state.turn_count
        st.info(f"ë‚¨ì€ í„´ ìˆ˜: {remaining_turns}")
    else:
        st.success("ëŒ€í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì±„íŒ…ì„ ì´ˆê¸°í™”í•˜ë ¤ë©´ ì‚¬ì´ë“œë°”ì˜ 'ì±„íŒ… ì´ˆê¸°í™”' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")

# ì±„íŒ… ì…ë ¥ (ì¡°ê±´ë¶€ë¡œ í™œì„±í™”)
if not st.session_state.chat_completed:
    if prompt := st.chat_input("ëŒ€í™”í•˜ê³  ì‹¶ì€ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ - ì±—ë´‡ ì•„ì´ì½˜ ì—†ì´ í‘œì‹œ
        st.markdown(
            f"<div class='user-bubble'>{prompt}</div>",
            unsafe_allow_html=True
        )
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ê¸°ë¡ì— ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
        generate_response(prompt)
        
        # ìµœëŒ€ í„´ ìˆ˜ ë„ë‹¬ ì²´í¬
        if st.session_state.turn_count >= st.session_state.max_turns:
            # í˜ì´ì§€ ë¦¬ë¡œë“œí•˜ì—¬ ì…ë ¥ì°½ ë¹„í™œì„±í™” ë° ì™„ë£Œ ë©”ì‹œì§€ í‘œì‹œ
            st.rerun()
else:
    # ì±„íŒ… ì¢…ë£Œ ìƒíƒœì¼ ë•Œ ì…ë ¥ì°½ ëŒ€ì‹  ë©”ì‹œì§€ í‘œì‹œ
    st.markdown(
        "<div style='text-align: center; padding: 15px; background-color: #f0f2f6; border-radius: 8px; margin-bottom: 20px;'>"
        "ëŒ€í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ë ¤ë©´ ì‚¬ì´ë“œë°”ì˜ 'ì±„íŒ… ì´ˆê¸°í™”' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”."
        "</div>",
        unsafe_allow_html=True
    )

# ì €ì¥ëœ í† í”½ìœ¼ë¡œ ëŒ€í™” ì‹œì‘í•˜ê¸°
if st.session_state.start_with_topic:
    prompt = st.session_state.start_with_topic
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ê¸°ë¡ì— ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
    generate_response(prompt)
    
    # ì‚¬ìš©í•œ í† í”½ ì´ˆê¸°í™”
    st.session_state.start_with_topic = None
    
    # í˜ì´ì§€ ë¦¬í”„ë ˆì‹œ
    st.rerun()