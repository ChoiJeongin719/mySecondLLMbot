import os
import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv
import json
import glob
import datetime  # For time measurement
import time  # Add this import for time.sleep()
import uuid
from supabase import create_client, Client

# Load environment variables from .env file
load_dotenv()

# Page configuration
st.set_page_config(
    page_title="Debate Chatbot",
    page_icon="ğŸ¤–",
    layout="wide"
)

# Initialize app state (to switch between chat and survey)
# ì°¸ê°€ì ID ê´€ë¦¬
if "participant_id" not in st.session_state:
    st.session_state.participant_id = ""

# ì•± ìƒíƒœ ê¸°ë³¸ê°’ì„ participant_idë¡œ ë³€ê²½
if "app_state" not in st.session_state:
    st.session_state.app_state = "participant_id"  # 'participant_id', 'chat', 'survey', 'complete'

# Initialize session state variables if they don't exist
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "\"ì£½ì€ ë°˜ë ¤ë™ë¬¼ì˜ ë³µì œ\"ì— ëŒ€í•œ ì£¼ì œë¡œ ì±—ë´‡ê³¼ 4í„´ì˜ ëŒ€í™”ë¥¼ ë‚˜ëˆŒ ê²ƒì…ë‹ˆë‹¤. ì²« ë²ˆì§¸ í„´ì„ ì‹œì‘í•˜ë ¤ë©´ ì§ˆë¬¸ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”. ê·¸ í›„ì—ëŠ” ììœ ë¡­ê²Œ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì—¬ ì„¸ ë²ˆì˜ ëŒ€í™”ë¥¼ ë” ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš” â€” í¼í”Œì´ì™€ ë…¸ë‘ì´ê°€ í•¨ê»˜ ì‘ë‹µí•  ê²ƒì…ë‹ˆë‹¤.", "type": "system"}]

if "system_message_pro" not in st.session_state:
    st.session_state.system_message_pro = "ì´ í”„ë¡¬í”„íŠ¸ëŠ” ì „ì²´ í† ë¡ ì˜ ì ˆë°˜ì…ë‹ˆë‹¤. 'í¼í”Œì´'ë¼ëŠ” ìºë¦­í„°ë¡œì„œ ë°˜ë ¤ë™ë¬¼ ë³µì œì— ì°¬ì„±í•˜ëŠ” ì…ì¥ì„ 4ë¬¸ì¥ìœ¼ë¡œ í•˜ë‚˜ì˜ ë‹¨ë½ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ë§íˆ¬ëŠ” ì¹œê·¼í•˜ì§€ë§Œ ëŒ€í™”ì²´ëŠ” í”¼í•˜ê³ , ì´ë¦„ ë¶€ë¥´ê¸° ì—†ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì¨ì£¼ì„¸ìš”."

if "system_message_con" not in st.session_state:
    st.session_state.system_message_con = "ì´ í”„ë¡¬í”„íŠ¸ëŠ” ë™ì¼í•œ ì£¼ì œì˜ ë°˜ëŒ€ ì…ì¥ì…ë‹ˆë‹¤. 'ë…¸ë‘ì´'ë¼ëŠ” ìºë¦­í„°ë¡œì„œ ë°˜ë ¤ë™ë¬¼ ë³µì œì— ë°˜ëŒ€í•˜ëŠ” ì…ì¥ì„ 4ë¬¸ì¥ìœ¼ë¡œ í•˜ë‚˜ì˜ ë‹¨ë½ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ë§íˆ¬ëŠ” ì¹œê·¼í•˜ì§€ë§Œ ëŒ€í™”ì²´ëŠ” í”¼í•˜ê³ , ì´ë¦„ ë¶€ë¥´ê¸° ì—†ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì¨ì£¼ì„¸ìš”."

if "usage_stats" not in st.session_state:
    st.session_state.usage_stats = []

if "show_process" not in st.session_state:
    st.session_state.show_process = False

# Session time measurement variables
if "session_start_time" not in st.session_state:
    st.session_state.session_start_time = datetime.datetime.now()

if "last_interaction_time" not in st.session_state:
    st.session_state.last_interaction_time = datetime.datetime.now()

if "total_session_duration" not in st.session_state:
    st.session_state.total_session_duration = datetime.timedelta(0)

if "interaction_count" not in st.session_state:
    st.session_state.interaction_count = 0

# Add conversation variables
if "conversation_started" not in st.session_state:
    st.session_state.conversation_started = False

if "current_turn" not in st.session_state:
    st.session_state.current_turn = 0

# í„´ ìˆ˜ ì„¤ì • ë³€ìˆ˜
if "max_turns" not in st.session_state:
    st.session_state.max_turns = 4  # ê¸°ë³¸ê°’

# Survey response
if "survey_response" not in st.session_state:
    st.session_state.survey_response = 5  # ê¸°ë³¸ê°’ (ì¤‘ê°„)

# ì‚¬ìš©ì ID ìƒì„± (ì„¸ì…˜ ì‹œì‘ì‹œ í•œë²ˆë§Œ)
if "user_id" not in st.session_state:
    st.session_state.user_id = str(uuid.uuid4())

# ìƒí˜¸ì‘ìš© ì‹œì‘ ì‹œê°„ ì¶”ì ì„ ìœ„í•œ ë³€ìˆ˜
if "interaction_start" not in st.session_state:
    st.session_state.interaction_start = None

# í† í° ì‚¬ìš©ëŸ‰ ì¶”ì ì„ ìœ„í•œ ë³€ìˆ˜
if "token_usage" not in st.session_state:
    st.session_state.token_usage = {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}

# Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
supabase_url = st.secrets["SUPABASE_URL"]
supabase_key = st.secrets["SUPABASE_KEY"]
supabase: Client = create_client(supabase_url, supabase_key)

# Usage time tracking function
def update_session_time():
    """Updates the usage time of the current session"""
    now = datetime.datetime.now()
    
    # If more than 10 minutes (600 seconds) have passed since the last interaction, consider it a new session
    time_diff = (now - st.session_state.last_interaction_time).total_seconds()
    if time_diff > 600:  # More than 10 minutes difference
        # Save previous session time
        session_duration = st.session_state.last_interaction_time - st.session_state.session_start_time
        st.session_state.total_session_duration += session_duration
        
        # Start new session
        st.session_state.session_start_time = now
    
    # Update last interaction time
    st.session_state.last_interaction_time = now
    
    # Increase interaction count
    st.session_state.interaction_count += 1

def get_openai_client():
    """Create and return an OpenAI client configured with environment variables"""
    token = os.getenv("GITHUB_TOKEN")
    endpoint = os.getenv("GITHUB_ENDPOINT", "https://models.github.ai/inference")
    
    if not token:
        st.error("GitHub token not found in environment variables. Please check your .env file.")
        st.stop()
        
    return OpenAI(
        base_url=endpoint,
        api_key=token,
    )

def generate_debate_responses(prompt):
    """Generate two separate responses - one pro, one con"""
    # Update interaction time
    update_session_time()
    
    client = get_openai_client()
    model_name = os.getenv("GITHUB_MODEL", "openai/gpt-4o")
    
    # Prepare previous conversation history (excluding the system message)
    history = []
    for msg in st.session_state.messages:
        if msg["role"] != "system" and "type" not in msg:  # Skip system messages
            history.append(msg)
    
    # Generate pro messages
    pro_messages = [{"role": "system", "content": st.session_state.system_message_pro}] + history + [{"role": "user", "content": prompt}]
    
    # Generate con messages
    con_messages = [{"role": "system", "content": st.session_state.system_message_con}] + history + [{"role": "user", "content": prompt}]
    
    try:
        # Display response in chat format
        status_placeholder = st.empty()
        status_placeholder.markdown("Generating response...", unsafe_allow_html=True)
        
        # Generate pro response
        full_pro_response = ""
        usage_pro = None
        
        pro_response = client.chat.completions.create(
            messages=pro_messages,
            model=model_name,
            stream=True,
            stream_options={'include_usage': True}
        )
        
        # Add pro response
        pro_placeholder = st.empty()
        
        # Stream pro response
        for chunk in pro_response:
            if chunk.choices and chunk.choices[0].delta.content:
                content_chunk = chunk.choices[0].delta.content
                full_pro_response += content_chunk
                pro_placeholder.markdown(
                    f"<div class='pro-name'>Purpli</div><div class='pro-bubble'>{full_pro_response}â–Œ</div>",
                    unsafe_allow_html=True
                )
                
            if chunk.usage:
                usage_pro = chunk.usage
        
        # Update final pro response (remove cursor)
        pro_placeholder.markdown(
            f"<div class='pro-name'>Purpli</div><div class='pro-bubble'>{full_pro_response}</div>",
            unsafe_allow_html=True
        )
        
        # Generate con response
        full_con_response = ""
        usage_con = None
        
        con_response = client.chat.completions.create(
            messages=con_messages,
            model=model_name,
            stream=True,
            stream_options={'include_usage': True}
        )
        
        # Add con response
        con_placeholder = st.empty()
        
        # Stream con response
        for chunk in con_response:
            if chunk.choices and chunk.choices[0].delta.content:
                content_chunk = chunk.choices[0].delta.content
                full_con_response += content_chunk
                con_placeholder.markdown(
                    f"<div class='con-name'>Yellowy</div><div class='con-bubble'>{full_con_response}â–Œ</div>",
                    unsafe_allow_html=True
                )
                
            if chunk.usage:
                usage_con = chunk.usage
        
        # Update final con response (remove cursor)
        con_placeholder.markdown(
            f"<div class='con-name'>Yellowy</div><div class='con-bubble'>{full_con_response}</div>",
            unsafe_allow_html=True
        )
        
        # Remove status display
        status_placeholder.empty()
        
        # Add responses to session state
        st.session_state.messages.append({"role": "assistant", "content": full_pro_response, "type": "pro"})
        st.session_state.messages.append({"role": "assistant", "content": full_con_response, "type": "con"})
        
        # Save usage statistics
        if usage_pro and usage_con:
            # Handle Pydantic models
            usage_pro_dict = usage_pro.model_dump() if hasattr(usage_pro, 'model_dump') else usage_pro.dict()
            usage_con_dict = usage_con.model_dump() if hasattr(usage_con, 'model_dump') else usage_con.dict()
            
            st.session_state.usage_stats.append({
                "prompt_tokens": usage_pro_dict.get("prompt_tokens", 0) + usage_con_dict.get("prompt_tokens", 0),
                "completion_tokens": usage_pro_dict.get("completion_tokens", 0) + usage_con_dict.get("completion_tokens", 0),
                "total_tokens": usage_pro_dict.get("total_tokens", 0) + usage_con_dict.get("total_tokens", 0)
            })
        
        # If process display is activated
        if st.session_state.show_process:
            process_container = st.container()
            with process_container:
                st.markdown("### Model Processing")
                
                # Display request details
                request_expander = st.expander("Request Details", expanded=False)
                with request_expander:
                    st.markdown("**Pro System Message:**")
                    st.code(st.session_state.system_message_pro)
                    st.markdown("**Con System Message:**")
                    st.code(st.session_state.system_message_con)
                    st.markdown("**User Input:**")
                    st.code(prompt)
                
                # Display raw responses
                response_expander = st.expander("Raw Responses", expanded=False)
                with response_expander:
                    st.markdown("**Pro Response:**")
                    st.code(full_pro_response, language="markdown")
                    st.markdown("**Con Response:**")
                    st.code(full_con_response, language="markdown")
                
                # Display usage statistics
                if usage_pro and usage_con:
                    usage_expander = st.expander("Usage Statistics", expanded=False)
                    with usage_expander:
                        st.markdown("**Pro Response Usage:**")
                        st.markdown(f"- Prompt tokens: {usage_pro_dict.get('prompt_tokens', 0)}")
                        st.markdown(f"- Completion tokens: {usage_pro_dict.get('completion_tokens', 0)}")
                        st.markdown(f"- Total tokens: {usage_pro_dict.get('total_tokens', 0)}")
                        
                        st.markdown("**Con Response Usage:**")
                        st.markdown(f"- Prompt tokens: {usage_con_dict.get('prompt_tokens', 0)}")
                        st.markdown(f"- Completion tokens: {usage_con_dict.get('completion_tokens', 0)}")
                        st.markdown(f"- Total tokens: {usage_con_dict.get('total_tokens', 0)}")
        
        # í„´ ìˆ˜ ì¦ê°€
        st.session_state.current_turn += 1
        
        return True
    except Exception as e:
        st.error(f"Error generating responses: {str(e)}")
        return False

# CSS style definition
st.markdown("""
    <style>
    .pro-bubble {
        background-color: #f1e5ff;
        padding: 12px;
        border-radius: 18px 18px 18px 0;
        margin-bottom: 16px;
        max-width: 68%;
        position: relative;
        margin-left: 50px;
        box-shadow: 0 1px 2px rgba(0,0,0,0.1);
    }

    .pro-bubble::before {
        content: "";
        width: 40px;
        height: 40px;
        border-radius: 50%;
        background-color: #9C27B0;  /* Purple color */
        position: absolute;
        left: -50px;
        top: 0;
        background-image: url('https://cdn-icons-png.flaticon.com/512/4712/4712035.png');
        background-size: 60%;
        background-position: center;
        background-repeat: no-repeat;
        box-shadow: 0 1px 2px rgba(0,0,0,0.1);
    }

    .con-bubble {
        background-color: #fffde7;
        padding: 12px;
        border-radius: 18px 18px 18px 0;
        margin-bottom: 16px;
        max-width: 68%;
        position: relative;
        margin-left: 50px;
        box-shadow: 0 1px 2px rgba(0,0,0,0.1);
    }

    .con-bubble::before {
        content: "";
        width: 40px;
        height: 40px;
        border-radius: 50%;
        background-color: #FFC107;  /* Yellow color */
        position: absolute;
        left: -50px;
        top: 0;
        background-image: url('https://cdn-icons-png.flaticon.com/512/4712/4712035.png');
        background-size: 60%;
        background-position: center;
        background-repeat: no-repeat;
        box-shadow: 0 1px 2px rgba(0,0,0,0.1);
    }

    .user-bubble {
        background-color: #e3f0fd;
        padding: 12px;
        border-radius: 18px 18px 0 18px;
        margin-bottom: 16px;
        text-align: left;
        max-width: 60%;
        margin-left: auto;
        box-shadow: 0 1px 2px rgba(0,0,0,0.1);
    }

    .system-bubble {
        background-color: #f8f9fa;
        padding: 12px;
        border-radius: 18px;
        margin-bottom: 16px;
        max-width: 70%;
        margin-left: auto;
        margin-right: auto;
        text-align: center;
        box-shadow: 0 1px 2px rgba(0,0,0,0.1);
    }

    .stChatFloatingInputContainer {
        position: fixed !important;
        bottom: 0 !important;
        padding: 1rem !important;
        width: calc(100% - 250px) !important; /* Sidebar width adjustment */
        background-color: white !important;
        z-index: 1000 !important;
    }

    .main-content {
        padding-bottom: 100px; /* Bottom margin for fixed input container */
    }

    .pro-name {
        font-size: 0.8em;
        color: #9C27B0;  /* Purple color */
        font-weight: bold;
        margin-bottom: 4px;
        margin-left: 0px;
    }

    .con-name {
        font-size: 0.8em;
        color: #FFC107;  /* Yellow color */
        font-weight: bold;
        margin-bottom: 4px;
        margin-left: 0px;
    }
    
    .starter-btn-box {
        display: flex;
        justify-content: flex-end;
        margin-bottom: 15px;
    }
    
    .next-button {
        background-color: #4CAF50;
        color: white;
        border: none;
        padding: 10px 20px;
        text-align: center;
        text-decoration: none;
        display: inline-block;
        font-size: 16px;
        margin: 20px 0;
        cursor: pointer;
        border-radius: 5px;
    }
    
    .survey-container {
        max-width: 800px;
        margin: 50px auto;
        padding: 30px;
        background-color: #f9f9f9;
        border-radius: 10px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }
    
    .survey-title {
        font-size: 24px;
        margin-bottom: 30px;
        text-align: center;
    }
    
    .slider-labels {
        display: flex;
        justify-content: space-between;
        margin-top: 5px;
        color: #666;
    }
    </style>
""", unsafe_allow_html=True)

# Supabaseì— ë°ì´í„° ì €ì¥ í•¨ìˆ˜ ì¶”ê°€
def save_to_supabase(score=None):
    """Supabaseì˜ LLM2 í…Œì´ë¸”ì— ë°ì´í„° ì €ì¥"""
    try:
        # ì‹œê°„ ì •ë³´ ê³„ì‚°
        if st.session_state.interaction_start:
            start_time = st.session_state.interaction_start
            end_time = datetime.datetime.now()
            elapsed = end_time - start_time
            duration_seconds = int(elapsed.total_seconds())  # ì´ˆ ë‹¨ìœ„ ì •ìˆ˜
            interaction_time = duration_seconds  # ì´ˆ ë‹¨ìœ„ ì •ìˆ˜ë¡œ ì €ì¥
        else:
            start_time = datetime.datetime.now()  # ì‹œì‘ ì‹œê°„ì´ ì—†ìœ¼ë©´ í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ì„¤ì •
            end_time = None
            interaction_time = None
        
        # í† í° ì‚¬ìš©ëŸ‰ ê³„ì‚° (ì‚¬ìš© í†µê³„ì—ì„œ ê³„ì‚°)
        if st.session_state.usage_stats:
            total_prompt = sum(u["prompt_tokens"] for u in st.session_state.usage_stats)
            total_completion = sum(u["completion_tokens"] for u in st.session_state.usage_stats)
            total_tokens = sum(u["total_tokens"] for u in st.session_state.usage_stats)
        else:
            total_prompt = 0
            total_completion = 0
            total_tokens = 0
        
        # ì €ì¥í•  ë°ì´í„° ì¤€ë¹„ (í…Œì´ë¸” êµ¬ì¡°ì— ë§ê²Œ ì¡°ì •)
        data = {
            # timestampëŠ” ê¸°ë³¸ê°’ now()ë¥¼ ì‚¬ìš©
            "user_id": st.session_state.user_id,
            "participant_id": st.session_state.participant_id,  # ì°¸ê°€ì ID ì¶”ê°€
            "started_at": start_time.isoformat() if start_time else None,  # ì‹œì‘ ì‹œê°„ ì¶”ê°€
            "finished_at": end_time.isoformat() if end_time else None,  # ì¢…ë£Œ ì‹œê°„ ì¶”ê°€
            "interaction_time": interaction_time,  # ì´ˆ ë‹¨ìœ„ ì •ìˆ˜ë¡œ ì €ì¥
            "total_tokens": total_tokens,
            "prompt_tokens": total_prompt,
            "completion_tokens": total_completion,
            "score": score,
            "messages": st.session_state.messages
        }
        
        # Supabaseì— ë°ì´í„° ì €ì¥ (LLM2 í…Œì´ë¸”ì— ì €ì¥)
        result = supabase.table("LLM2").insert(data).execute()
        
        # ì €ì¥ ì„±ê³µ ì—¬ë¶€ í™•ì¸
        if result.data:
            return True
        return False
    
    except Exception as e:
        st.error(f"ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

# ì°¸ê°€ì ID ê²€ì¦ í•¨ìˆ˜ ìˆ˜ì • (ì•½ 495ì¤„ ê·¼ì²˜)
def validate_participant_id(participant_id):
    """
    Supabaseì˜ participants í…Œì´ë¸”ì—ì„œ ì°¸ê°€ì ID ìœ íš¨ì„± ê²€ì¦
    
    Returns:
        (bool, str): (ìœ íš¨ì„± ì—¬ë¶€, ë©”ì‹œì§€)
    """
    try:
        # ë§ˆìŠ¤í„°í‚¤ í™•ì¸
        if participant_id == "j719":
            return True, "ê´€ë¦¬ì ì ‘ì† í™•ì¸ ì™„ë£Œ"
        
        # í˜•ì‹ ê²€ì‚¬: a, b, c, dë¡œ ì‹œì‘í•˜ê³  ë’¤ì— 3ìë¦¬ ìˆ«ì (001~100)
        import re
        if not re.match(r'^[a-d][0-9]{3}$', participant_id):
            return False, "ìœ íš¨í•˜ì§€ ì•Šì€ ì°¸ê°€ì ë²ˆí˜¸ í˜•ì‹ì…ë‹ˆë‹¤. a, b, c, d + 3ìë¦¬ ìˆ«ì í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: a001)"
        
        # ìˆ«ì ë¶€ë¶„ì´ 001~100 ë²”ìœ„ì¸ì§€ í™•ì¸
        num_part = int(participant_id[1:])
        if num_part < 1 or num_part > 100:
            return False, "ìœ íš¨í•˜ì§€ ì•Šì€ ì°¸ê°€ì ë²ˆí˜¸ì…ë‹ˆë‹¤. 1~100 ë²”ìœ„ì˜ ìˆ«ìë§Œ í—ˆìš©ë©ë‹ˆë‹¤."
        
        # Supabaseì—ì„œ í•´ë‹¹ ID ì¡°íšŒ
        result = supabase.table("participants").select("*").eq("id", participant_id).execute()
        
        # participants í…Œì´ë¸”ì— í•´ë‹¹ IDê°€ ì—†ìœ¼ë©´
        if not result.data:
            return False, "ë“±ë¡ë˜ì§€ ì•Šì€ ì°¸ê°€ì ë²ˆí˜¸ì…ë‹ˆë‹¤."
        
        # IDê°€ ì´ë¯¸ ì‚¬ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸
        if result.data[0].get("used", False):
            return False, "ì´ë¯¸ ì‚¬ìš©ëœ ì°¸ê°€ì ë²ˆí˜¸ì…ë‹ˆë‹¤."
        
        # ìœ íš¨í•œ IDê°€ ìˆìœ¼ë©´ ì‚¬ìš© ìƒíƒœ ì—…ë°ì´íŠ¸
        supabase.table("participants").update({"used": True, "used_at": datetime.datetime.now().isoformat()}).eq("id", participant_id).execute()
        return True, "ì°¸ê°€ì í™•ì¸ ì™„ë£Œ"
    
    except Exception as e:
        st.error(f"ì°¸ê°€ì ID ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False, f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ì°¸ê°€ì ID ì…ë ¥ í˜ì´ì§€ í•¨ìˆ˜ ì¶”ê°€ (show_chat_page í•¨ìˆ˜ ìœ„ì— ì¶”ê°€)
def show_participant_id_page():
    st.title("ì°¸ê°€ì ì •ë³´ ì…ë ¥")
    
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        st.markdown("### ì°¸ê°€ì ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”")
        st.markdown("ì‹¤í—˜ ì°¸ì—¬ë¥¼ ìœ„í•´ ì œê³µë°›ì€ ì°¸ê°€ì ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        
        # ì°¸ê°€ì ID ì…ë ¥ í•„ë“œ
        participant_id = st.text_input(
            "ì°¸ê°€ì ë²ˆí˜¸", 
            value=st.session_state.participant_id,
            key="participant_id_input",
            placeholder="ì˜ˆ: a001"
        )
        
        # ì‹¤í—˜ ì‹œì‘ ë²„íŠ¼
        if st.button("ì‹¤í—˜ ì‹œì‘í•˜ê¸°", type="primary", key="start_experiment_btn"):
            # ì°¸ê°€ì ID ê²€ì¦
            valid, message = validate_participant_id(participant_id)
            
            if valid:
                st.session_state.participant_id = participant_id
                st.session_state.app_state = "chat"
                st.success(message)
                time.sleep(1)  # ì„±ê³µ ë©”ì‹œì§€ ì ì‹œ í‘œì‹œ
                st.rerun()
            else:
                st.error(message)

# ëŒ€í™” í˜ì´ì§€
def show_chat_page():
    # ìƒë‹¨ì— ì°¸ê°€ì ID í‘œì‹œ ì¶”ê°€
    st.markdown(f"<div style='text-align: right; font-size: 0.8em; color: #666;'>ì°¸ê°€ì ë²ˆí˜¸: {st.session_state.participant_id}</div>", unsafe_allow_html=True)
    
    # Sidebar settings
    with st.sidebar:
        st.subheader("Settings")
        
        # ëŒ€í™” í„´ ìˆ˜ ì„¤ì • ìŠ¬ë¼ì´ë” ì¶”ê°€
        st.session_state.max_turns = st.slider(
            "Number of conversation turns", 
            min_value=1, 
            max_value=10, 
            value=st.session_state.max_turns,
            step=1
        )
        
        st.markdown(f"**Current turn: {st.session_state.current_turn}/{st.session_state.max_turns}**")
        
        # Display time statistics
        with st.expander("Usage Time Statistics", expanded=False):
            # Calculate current session
            current_session_duration = st.session_state.last_interaction_time - st.session_state.session_start_time
            total_time = st.session_state.total_session_duration + current_session_duration
            
            # Format time (hours:minutes:seconds)
            def format_timedelta(td):
                total_seconds = int(td.total_seconds())
                hours = total_seconds // 3600
                minutes = (total_seconds % 3600) // 60
                seconds = total_seconds % 60
                return f"{hours:02d}:{minutes:02d}:{seconds:02d}"
            
            st.write("### Usage Time")
            st.write(f"Current session: {format_timedelta(current_session_duration)}")
            st.write(f"Total usage time: {format_timedelta(total_time)}")
            st.write(f"Total interactions: {st.session_state.interaction_count}")
            st.write(f"First usage time: {st.session_state.session_start_time.strftime('%Y-%m-%d %H:%M:%S')}")
            st.write(f"Last usage time: {st.session_state.last_interaction_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # Edit pro system message
        st.text_area(
            "Pro Chatbot Settings", 
            value=st.session_state.system_message_pro,
            key="system_message_pro_input",
            height=150
        )
        
        # Edit con system message
        st.text_area(
            "Con Chatbot Settings", 
            value=st.session_state.system_message_con,
            key="system_message_con_input",
            height=150
        )
        
        if st.button("Update System Messages"):
            st.session_state.system_message_pro = st.session_state.system_message_pro_input
            st.session_state.system_message_con = st.session_state.system_message_con_input
            st.success("System messages have been updated!")
        
        # Other sidebar elements
        st.markdown("---")
        
        # View chat history
        with st.expander("View Chat History"):
            st.json(st.session_state.messages)
        
        # View usage statistics
        with st.expander("View Usage Statistics"):
            if st.session_state.usage_stats:
                for i, usage in enumerate(st.session_state.usage_stats):
                    st.write(f"Message {i+1}:")
                    st.write(f"- Prompt tokens: {usage['prompt_tokens']}")
                    st.write(f"- Completion tokens: {usage['completion_tokens']}")
                    st.write(f"- Total tokens: {usage['total_tokens']}")
                    st.divider()
                
                # Calculate total usage
                total_prompt = sum(u["prompt_tokens"] for u in st.session_state.usage_stats)
                total_completion = sum(u["completion_tokens"] for u in st.session_state.usage_stats)
                total = sum(u["total_tokens"] for u in st.session_state.usage_stats)
                
                st.write("### Total Usage")
                st.write(f"- Total prompt tokens: {total_prompt}")
                st.write(f"- Total completion tokens: {total_completion}")
                st.write(f"- Total tokens: {total}")
            else:
                st.write("No usage data available yet.")
        
        # Reset chat button
        if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
            st.session_state.messages = [{"role": "assistant", "content": "\"ì£½ì€ ë°˜ë ¤ë™ë¬¼ì˜ ë³µì œ\"ì— ëŒ€í•œ ì£¼ì œë¡œ ì±—ë´‡ê³¼ 4í„´ì˜ ëŒ€í™”ë¥¼ ë‚˜ëˆŒ ê²ƒì…ë‹ˆë‹¤. ì²« ë²ˆì§¸ í„´ì„ ì‹œì‘í•˜ë ¤ë©´ ì§ˆë¬¸ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”. ê·¸ í›„ì—ëŠ” ììœ ë¡­ê²Œ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì—¬ ì„¸ ë²ˆì˜ ëŒ€í™”ë¥¼ ë” ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš” â€” í¼í”Œì´ì™€ ë…¸ë‘ì´ê°€ í•¨ê»˜ ì‘ë‹µí•  ê²ƒì…ë‹ˆë‹¤.", "type": "system"}]
            st.session_state.usage_stats = []
            st.session_state.conversation_started = False
            st.session_state.current_turn = 0
            
            # Reset time variables
            now = datetime.datetime.now()
            st.session_state.session_start_time = now
            st.session_state.last_interaction_time = now
            st.session_state.total_session_duration = datetime.timedelta(0)
            st.session_state.interaction_count = 0
            
            st.success("ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        # Process display toggle
        st.markdown("---")
        st.session_state.show_process = st.checkbox("Show model processing", value=st.session_state.show_process)

    # Main chat area
    chat_container = st.container()
    with chat_container:
        st.markdown('<div class="main-content">', unsafe_allow_html=True)
        
        # ê°€ì¥ ë¨¼ì € ì‹œìŠ¤í…œ ë©”ì‹œì§€ í‘œì‹œ
        system_message_shown = False
        
        # Process chat history in order
        i = 0
        while i < len(st.session_state.messages):
            message = st.session_state.messages[i]
            
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” í•œ ë²ˆë§Œ í‘œì‹œ
            if message["role"] == "assistant" and "type" in message and message["type"] == "system":
                if not system_message_shown:
                    st.markdown(
                        f"<div class='system-bubble'>{message['content']}</div>",
                        unsafe_allow_html=True
                    )
                    system_message_shown = True
                    
                    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ë°”ë¡œ ë‹¤ìŒì— ëŒ€í™” ìŠ¤íƒ€í„° ë²„íŠ¼ ë°°ì¹˜
                    col1, col2 = st.columns([3, 1])
                    with col2:
                        if not st.session_state.conversation_started and st.button(
                            "í¼í”Œì•„, ë…¸ë‘ì•„, ì£½ì€ ë°˜ë ¤ë™ë¬¼ì˜ ë³µì œì— ëŒ€í•´ ì•Œë ¤ì¤„ë˜?",
                            key="conversation_starter"
                        ):
                            # ìƒí˜¸ì‘ìš© ì‹œì‘ ì‹œê°„ ê¸°ë¡
                            st.session_state.interaction_start = datetime.datetime.now()
                            
                            st.session_state.conversation_started = True
                            st.session_state.current_turn = 1
                            user_prompt = "í¼í”Œì•„, ë…¸ë‘ì•„, ì£½ì€ ë°˜ë ¤ë™ë¬¼ì˜ ë³µì œì— ëŒ€í•´ ì•Œë ¤ì¤„ë˜?"
                            st.session_state.messages.append({"role": "user", "content": user_prompt})
                            
                            # ê³ ì •ëœ ì²« ì‘ë‹µ (purpli_responseì™€ yellowy_response ë³€ìˆ˜ ìˆ˜ì •)
                            purpli_response = "ì£½ì€ ë°˜ë ¤ë™ë¬¼ì„ ë³µì œí•˜ëŠ” ê±´ ìƒëª…ê³µí•™ ê¸°ìˆ ë¡œ ì›ë˜ ë™ë¬¼ê³¼ ìœ ì „ì ìœ¼ë¡œ ë˜‘ê°™ì€ ìƒˆë¡œìš´ ë™ë¬¼ì„ ë§Œë“œëŠ” ê±°ì•¼. ë§ì€ ì‚¬ëŒë“¤ì—ê²Œ ë°˜ë ¤ë™ë¬¼ì€ ê°€ì¡± ê°™ì€ ì¡´ì¬ë‹ˆê¹Œ, ì–´ë–¤ í˜•íƒœë¡œë“  ë‹¤ì‹œ ë§Œë‚  ìˆ˜ ìˆë‹¤ëŠ” ìƒê° ìì²´ê°€ í° ìœ„ë¡œê°€ ë  ìˆ˜ ìˆì–´. ìš”ì¦˜ ê¸°ìˆ ì´ ë§ì´ ë°œë‹¬í•´ì„œ ë³µì œë„ í˜„ì‹¤ì ìœ¼ë¡œ ê°€ëŠ¥í•œ ì„ íƒì§€ê°€ ëê³ . ë˜ ì–´ë–¤ ì‚¬ëŒë“¤ì€ íŠ¹ë³„í•œ ë™ë¬¼ë“¤, ì˜ˆë¥¼ ë“¤ì–´ ì•ˆë‚´ê²¬ì´ë‚˜ ê²½ì°°ê²¬ ê°™ì€ ì•„ì´ë“¤ì˜ ìœ ì „ìë¥¼ ë³µì œë¥¼ í†µí•´ ë³´ì¡´í•  ê°€ì¹˜ê°€ ìˆë‹¤ê³  ìƒê°í•˜ê¸°ë„ í•´."
                            yellowy_response = "ì£½ì€ ë°˜ë ¤ë™ë¬¼ ë³µì œëŠ” ê½¤ ë³µì¡í•œ ê³¼ì •ì„ ê±°ì³ì•¼ í•´. ë³´ì¡´ëœ ì¡°ì§ì—ì„œ DNAë¥¼ ì¶”ì¶œí•˜ê³ , ë°°ì•„ë¥¼ ë§Œë“¤ì–´ì„œ ëŒ€ë¦¬ëª¨ì—ê²Œ ì´ì‹í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•˜ê±°ë“ . ë³µì œëœ ë°˜ë ¤ë™ë¬¼ì´ ë˜‘ê°™ì´ ìƒê¸°ê³  ê°™ì€ ìœ ì „ìë¥¼ ê°€ì ¸ë„, ì˜ˆì „ì˜ ê¸°ì–µì´ë‚˜ ì„±ê²©ì€ ë˜‘ê°™ì§€ ì•Šì„ ê±°ê³ , ìƒì‹¤ê°ì€ ì—¬ì „íˆ ë‚¨ì„ ìˆ˜ ìˆì–´. ê·¸ë¦¬ê³  ì…ì–‘ì„ ê¸°ë‹¤ë¦¬ëŠ” ìœ ê¸°ë™ë¬¼ë“¤ì´ ì •ë§ ë§ì€ë°, ë³µì œë³´ë‹¤ëŠ” ê·¸ëŸ° ì•„ì´ë“¤ì„ ëŒë³´ëŠ” ê²Œ ë” ì˜ë¯¸ ìˆëŠ” ì„ íƒì¼ ìˆ˜ë„ ìˆì–´."
                            
                            st.session_state.messages.append({"role": "assistant", "content": purpli_response, "type": "pro"})
                            st.session_state.messages.append({"role": "assistant", "content": yellowy_response, "type": "con"})
                            
                            st.rerun()
                i += 1
            elif message["role"] == "user":
                # User message
                st.markdown(
                    f"<div class='user-bubble'>{message['content']}</div>",
                    unsafe_allow_html=True
                )
                i += 1
            elif message["role"] == "assistant" and "type" in message and message["type"] == "pro":
                # Pro message - display with purple profile and name "Purpli"
                st.markdown(
                    f"<div class='pro-name'>Purpli</div><div class='pro-bubble'>{message['content']}</div>",
                    unsafe_allow_html=True
                )
                i += 1
            elif message["role"] == "assistant" and "type" in message and message["type"] == "con":
                # Con message - display with yellow profile and name "Yellowy"
                st.markdown(
                    f"<div class='con-name'>Yellowy</div><div class='con-bubble'>{message['content']}</div>",
                    unsafe_allow_html=True
                )
                i += 1
            else:
                # Other messages
                st.markdown(
                    f"<div class='system-bubble'>{message['content']}</div>",
                    unsafe_allow_html=True
                )
                i += 1
        
        # ëŒ€í™” í„´ ìˆ˜ê°€ ìµœëŒ€ì— ë„ë‹¬í–ˆìœ¼ë©´ Next ë²„íŠ¼ í‘œì‹œ
        if st.session_state.conversation_started and st.session_state.current_turn >= st.session_state.max_turns:
            st.markdown("<div style='text-align: center; margin-top: 30px;'>ìµœëŒ€ ëŒ€í™” í„´ ìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.</div>", unsafe_allow_html=True)
            
            # Next ë²„íŠ¼
            if st.button("ë‹¤ìŒ", key="next_to_survey", type="primary"):
                st.session_state.app_state = "survey"
                st.rerun()
        
        st.markdown('</div>', unsafe_allow_html=True)

    # Chat input (Only show if conversation not finished)
    if st.session_state.conversation_started and st.session_state.current_turn < st.session_state.max_turns:
        if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
            # Display user message without chatbot icon
            st.markdown(
                f"<div class='user-bubble'>{prompt}</div>",
                unsafe_allow_html=True
            )
            
            # Add user message to history
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            # Generate and display pro/con responses
            generate_debate_responses(prompt)
            
            # Force rerun to update the UI
            st.rerun()

# ì„¤ë¬¸ì¡°ì‚¬ í˜ì´ì§€
def show_survey_page():
    st.markdown("<h2>ì„¤ë¬¸ì¡°ì‚¬</h2>", unsafe_allow_html=True)
    st.markdown("**ì´ ì±—ë´‡ê³¼ ë” ëŒ€í™”í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?**")
    
    # ìŠ¬ë¼ì´ë” UI ê°œì„  - 3ê°œì˜ ì—´ ì‚¬ìš©
    col1, col2, col3 = st.columns([1, 10, 1])
    
    with col1:
        st.markdown("<div style='text-align: center; font-size: 0.9em;'>(ë™ì˜í•˜ì§€ ì•ŠìŒ)</div>", unsafe_allow_html=True)
        
    with col2:
        # ë¼ë²¨ ìˆ¨ê¸°ê¸°
        st.session_state.survey_response = st.slider("", 1, 9, st.session_state.survey_response, label_visibility="collapsed")
        
    with col3:
        st.markdown("<div style='text-align: center; font-size: 0.9em;'>(ë™ì˜í•¨)</div>", unsafe_allow_html=True)
    
    # ì œì¶œ ë²„íŠ¼ ì¤‘ì•™ ì •ë ¬
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        if st.button("ì„¤ë¬¸ ì œì¶œ", type="primary", key="survey_submit"):
            # Supabaseì— ë°ì´í„° ì €ì¥
            if save_to_supabase(st.session_state.survey_response):
                st.success(f"í”¼ë“œë°±ì— ê°ì‚¬ë“œë¦½ë‹ˆë‹¤! ì ìˆ˜: {st.session_state.survey_response}")
            else:
                st.warning("í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆì§€ë§Œ, ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ì— ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤.")
            
            # ì¼ì • ì‹œê°„ í›„ ì™„ë£Œ í˜ì´ì§€ë¡œ ì´ë™
            time.sleep(2)
            
            # ì™„ë£Œ í˜ì´ì§€ë¡œ ì´ë™
            st.session_state.app_state = "complete"
            st.rerun()
    
    st.markdown("</div>", unsafe_allow_html=True)

# ì‹¤í—˜ ì™„ë£Œ í˜ì´ì§€ í•¨ìˆ˜ ì¶”ê°€ (show_survey_page í•¨ìˆ˜ ë‹¤ìŒì— ì¶”ê°€)
def show_complete_page():
    st.title("ì‹¤í—˜ ì™„ë£Œ")
    
    # ì¤‘ì•™ì— ë©”ì‹œì§€ í‘œì‹œ
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        st.markdown("### ì‹¤í—˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.markdown("êµ¬ê¸€í¼ì—ì„œ ì„¤ë¬¸ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”. ì°¸ì—¬í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.")
        
        # ë‹¤ì‹œ ì‹œì‘ ë²„íŠ¼ (ì„ íƒì )
        if st.button("ìƒˆë¡œìš´ ì‹¤í—˜ ì‹œì‘", key="restart_btn"):
            # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.app_state = "participant_id"
            st.session_state.participant_id = ""
            st.session_state.messages = [{"role": "assistant", "content": "\"ì£½ì€ ë°˜ë ¤ë™ë¬¼ì˜ ë³µì œ\"ì— ëŒ€í•œ ì£¼ì œë¡œ ì±—ë´‡ê³¼ 4í„´ì˜ ëŒ€í™”ë¥¼ ë‚˜ëˆŒ ê²ƒì…ë‹ˆë‹¤. ì²« ë²ˆì§¸ í„´ì„ ì‹œì‘í•˜ë ¤ë©´ ì§ˆë¬¸ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”. ê·¸ í›„ì—ëŠ” ììœ ë¡­ê²Œ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì—¬ ì„¸ ë²ˆì˜ ëŒ€í™”ë¥¼ ë” ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš” â€” í¼í”Œì´ì™€ ë…¸ë‘ì´ê°€ í•¨ê»˜ ì‘ë‹µí•  ê²ƒì…ë‹ˆë‹¤.", "type": "system"}]
            st.session_state.conversation_started = False
            st.session_state.current_turn = 0
            st.session_state.interaction_start = None
            st.session_state.usage_stats = []
            st.rerun()

# ì•± ìƒíƒœì— ë”°ë¼ ì ì ˆí•œ í˜ì´ì§€ í‘œì‹œ
if st.session_state.app_state == "participant_id":
    show_participant_id_page()
elif st.session_state.app_state == "chat":
    show_chat_page()
elif st.session_state.app_state == "survey":
    show_survey_page()
elif st.session_state.app_state == "complete":
    show_complete_page()